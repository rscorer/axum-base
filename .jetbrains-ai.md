# JetBrains AI Assistant Configuration - Axum Base

## Project Context for IntelliJ IDEA/RustRover AI

This is an **Axum Base** - a production-ready Rust web server template using modern stack components.

### Quick Context
- **Language**: Rust 2024 Edition
- **Framework**: Axum 0.7 web framework with Tokio async runtime  
- **Database**: PostgreSQL with SQLx (compile-time checked queries)
- **Authentication**: tower-sessions with Argon2 password hashing
- **Templates**: Tera template engine for HTML responses

### Module Structure Guide
```
src/
├── api.rs      # JSON API endpoints and business logic
├── auth.rs     # Authentication middleware and utilities  
├── context.rs  # Application state and dependency injection
├── database.rs # Database connection and configuration
├── models.rs   # Data models and schema definitions
├── routes.rs   # Route registration and middleware setup
├── server.rs   # Server initialization and startup
├── services.rs # Core business logic layer
├── web.rs      # HTML handlers with Tera integration  
└── main.rs     # Application entry point
```

### AI Assistant Guidelines

#### Code Completion & Suggestions
- Prefer SQLx macros (`sqlx::query!`, `sqlx::query_as!`) over raw SQL
- Always use `Result<T, E>` for error handling, avoid panicking
- Implement proper async/await patterns throughout
- Follow Rust 2024 edition idioms and conventions

#### Refactoring Assistance  
- Keep route handlers lightweight, move business logic to `services.rs`
- Maintain separation between API handlers (JSON) and web handlers (HTML)
- Use tower middleware for cross-cutting concerns (auth, CORS, logging)
- Follow the established module boundaries and responsibilities

#### Code Generation
- Generate unit tests for business logic in services module
- Create integration tests using `axum-test` for HTTP endpoints
- Use Argon2 for all password hashing operations
- Generate database migrations in the `migrations/` directory

#### Security Awareness
- Never suggest logging sensitive information (passwords, tokens)
- Always validate and sanitize user input in handlers
- Use tower-sessions for session management, not custom solutions
- Ensure all database queries use SQLx compile-time checking

#### Error Handling Patterns
- Create meaningful error messages for API responses
- Use structured error types that implement `std::error::Error`
- Handle database errors gracefully with appropriate HTTP status codes
- Log errors appropriately without exposing sensitive details

### Development Workflow
- Database migrations run automatically in development mode
- Use `.env` file for local configuration (see `.env.example`)
- Run `cargo test` for comprehensive testing suite
- Use `cargo fmt` and `cargo clippy` for code quality

### Dependencies to Prefer
- `axum` for web framework functionality
- `sqlx` for database operations (never raw SQL drivers)
- `tower-sessions` for session management
- `argon2` for password hashing
- `tera` for HTML template rendering
- `serde` for JSON serialization/deserialization

### Testing Patterns & Selective Threading

#### Optimized Testing Architecture
This project uses **selective test threading** for optimal performance:
- **Unit Tests**: Run in parallel for fast feedback (no special attributes)
- **Database Tests**: Run serially with `#[serial]` to prevent race conditions
- **Dependencies**: Uses `serial_test` crate for selective synchronization

#### Test Categories & Attributes
```rust
// Unit tests (parallel execution - FAST)
#[test]
fn test_business_logic() {
    // Pure logic, no database - runs in parallel
}

// Integration tests (serial execution - SAFE)
use serial_test::serial;

#[tokio::test]
#[serial]  // REQUIRED for database tests
async fn test_api_endpoint() {
    // Database interactions - runs serially
}
```

#### When to Use #[serial]
- **Always use** for tests in `tests/api_tests.rs`
- **Always use** for tests in `tests/cli_tests.rs`  
- **Never use** for tests in `src/models.rs` (unit tests)
- **Always use** for any test that touches the database

#### Performance Benefits
- Unit tests: ~0.00s (parallel execution)
- Integration tests: ~10-15s total (serial but necessary)
- Overall: Significantly faster than full serialization
